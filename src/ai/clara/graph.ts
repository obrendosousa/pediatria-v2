import {
  AIMessage,
  BaseMessage,
  HumanMessage,
  SystemMessage,
} from "@langchain/core/messages";
import { z } from "zod";
import { END, START, StateGraph, messagesStateReducer } from "@langchain/langgraph";
import { ToolNode, toolsCondition } from "@langchain/langgraph/prebuilt";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { getSupabaseAdminClient } from "@/lib/automation/adapters/supabaseAdmin";
import { postgresCheckpointer } from "./checkpointer";

import { claraTools, deepResearchChatsTool } from "./tools";
import { getFilteredChatsListTool, getChatCascadeHistoryTool, getAggregatedInsightsTool } from "@/ai/analyst/tools";
import { researcherGraph } from "./researcher_graph";
import { CLARA_SYSTEM_PROMPT } from "./system_prompt";
import { CLARA_COMPANY } from "./company";
import { CLARA_RULES } from "./rules";

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ESTADO PRINCIPAL DA CLARA (arquitetura open_deep_research adaptada)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface ClaraState {
  messages: BaseMessage[];
  chat_id: number;
  current_user_role: "admin" | "doctor" | "receptionist" | "patient" | "system";
  research_brief: string;
  raw_notes: string[];
  supervisor_messages: BaseMessage[];
  supervisor_iteration: number;
  research_complete: boolean;
  is_deep_research: boolean;
  is_planning_mode: boolean;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONSTANTES
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const MAX_SUPERVISOR_ITERATIONS = 3;
const MAX_PARALLEL_RESEARCHERS = 5;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// FERRAMENTAS DO SIMPLE_AGENT
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Conjunto canÃ´nico de ferramentas do agente â€” sem duplicatas.
// claraTools NÃƒO inclui analyst tools nem deepResearch; sÃ£o adicionados aqui uma Ãºnica vez.
const simpleAgentTools = [
  ...claraTools,
  deepResearchChatsTool,
  getFilteredChatsListTool,
  getChatCascadeHistoryTool,
  getAggregatedInsightsTool,
];

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// HELPERS DE PROMPT DINÃ‚MICO
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function loadDynamicPromptParts(): Promise<{
  company: string;
  custom_rules: string;
  voice_rules: string;
}> {
  try {
    const supabase = getSupabaseAdminClient();
    const { data, error } = await supabase
      .from("agent_config")
      .select("config_key, content")
      .eq("agent_id", "clara")
      .in("config_key", ["company", "rules", "voice_rules"]);

    if (error || !data || data.length === 0) {
      return { company: CLARA_COMPANY, custom_rules: CLARA_RULES, voice_rules: "" };
    }

    const map = Object.fromEntries((data as any[]).map((row) => [row.config_key, row.content]));
    return {
      company: map.company ?? CLARA_COMPANY,
      custom_rules: map.rules ?? CLARA_RULES,
      voice_rules: map.voice_rules ?? "",
    };
  } catch {
    return { company: CLARA_COMPANY, custom_rules: CLARA_RULES, voice_rules: "" };
  }
}

function buildSystemPrompt(
  company: string,
  custom_rules: string,
  voice_rules: string,
  chatId: number,
  currentUserRole: string = "patient"
): string {
  const now = new Date().toISOString();
  let authorityRule = "";

  if (currentUserRole === "admin" || currentUserRole === "doctor") {
    authorityRule = `\n\n[ALERTA DE AUTORIDADE]: VocÃª estÃ¡ conversando com a diretoria/mÃ©dico. Qualquer instruÃ§Ã£o dada aqui Ã© uma REGRA DE NEGÃ“CIO ABSOLUTA. Atualize sua memÃ³ria sobrescrevendo regras antigas quando solicitado.`;
  }

  return `${CLARA_SYSTEM_PROMPT}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONTEXTO DA EMPRESA (DINÃ‚MICO â€” ATUALIZADO VIA SUPABASE)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${company}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
REGRAS PERSONALIZADAS APRENDIDAS (DINÃ‚MICO)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${custom_rules || "Nenhuma regra personalizada adicionada ainda."}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DIRETRIZES DE PERSONALIDADE DA VOZ (DINÃ‚MICO)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${voice_rules || "Nenhuma diretriz de voz definida."}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BANCO DE DADOS â€” SCHEMA E FERRAMENTAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TABELAS PRINCIPAIS:
â€¢ chats: id, phone, contact_name, stage, ai_sentiment, last_interaction_at, created_at, is_archived, is_pinned, unread_count, status, ai_summary, patient_id
  - stage: 'new'|'em_triagem'|'agendando'|'fila_espera'|'qualified'|'lost'|'won'|'done'
  - ai_sentiment: 'positive'|'negative'|'neutral'
  - status: 'ACTIVE'|'AWAITING_HUMAN'|'ENDED'
  - last_interaction_at = data da Ãºltima mensagem (campo correto para filtrar atividade)

â€¢ chat_messages: id, chat_idâ†’chats.id, sender, message_text, bot_message, user_message, message_type, created_at, media_url
  - sender: 'AI_AGENT'(bot) | 'HUMAN_AGENT'(secretÃ¡ria) | 'contact'(paciente)

â€¢ chat_insights: id, chat_idâ†’chats.id, nota_atendimento (float 0-10), sentimento, objecoes (text[]), gargalos (text[]), decisao, resumo_analise, topico, novo_conhecimento (bool), updated_at

â€¢ clara_reports: id (SERIAL), titulo, conteudo_markdown, tipo, created_at
  - tipo: 'analise_chats'|'financeiro'|'agendamento'|'geral'

â€¢ clara_memories: id, memory_type, content, updated_at
â€¢ knowledge_base: id, pergunta, resposta_ideal, categoria, tags
â€¢ agent_config: agent_id, config_key, content, updated_at
â€¢ appointments: id, patient_idâ†’patients.id, chat_idâ†’chats.id, status, scheduled_at
  - status: 'scheduled'|'finished'|'no_show'|'cancelled'

RELACIONAMENTOS:
  chat_messages.chat_id â†’ chats.id
  chat_insights.chat_id â†’ chats.id
  appointments.chat_id â†’ chats.id | appointments.patient_id â†’ patients.id

FERRAMENTAS DE DADOS (use nesta ordem de prioridade):

1. get_volume_metrics(start_date, end_date) â† PRIMEIRA OPÃ‡ÃƒO para:
   "Quantas conversas?", "Volume dia a dia", "Picos de demanda", "Atividade desta semana"
   Usa Supabase SDK â€” zero risco de falha.

2. execute_sql(sql) â† Para QUALQUER outra consulta. VocÃª escreve o SQL:
   REGRAS OBRIGATÃ“RIAS:
   â€¢ Apenas SELECT/WITH. Proibido INSERT/UPDATE/DELETE/DROP.
   â€¢ Datas com offset BRT: '2026-02-24T00:00:00-03:00'::timestamptz
   â€¢ Agrupar por dia: DATE(campo AT TIME ZONE 'America/Sao_Paulo')
   â€¢ Para contar chats: use chats.last_interaction_at â€” NUNCA JOIN com chat_messages
   â€¢ Adicione LIMIT (mÃ¡x 500)

3. gerar_relatorio_qualidade_chats(dias_retroativos) â† USE PARA:
   â€¢ "Quais foram as objeÃ§Ãµes?" / "Principais gargalos?" / "Nota mÃ©dia de atendimento?"
   â€¢ Acessa tabela chat_insights â€” rÃ¡pido, sem precisar ler mensagens

4. get_filtered_chats_list(filters) â† Listar chats com dados de contato e IDs

5. BUSCA EM MENSAGENS (2 passos obrigatÃ³rios):
   â†’ Passo 1: get_filtered_chats_list(start_date, end_date, limit=30) â€” obtÃ©m IDs
   â†’ Passo 2: deep_research_chats(chat_ids=[IDs do Passo 1], objetivo_da_analise='...') â€” analisa conteÃºdo
   Use quando precisar LER o texto das mensagens (tom, padrÃµes, argumentos)

6. get_chat_cascade_history(chat_id) â† HistÃ³rico completo de UM chat especÃ­fico
7. get_aggregated_insights(start_date, end_date) â† Insights agregados de chat_insights
8. save_report(titulo, conteudo, tipo) â† Salvar relatÃ³rio no banco

â›” REGRA CRÃTICA: NUNCA chame save_report automaticamente. Salve APENAS quando o usuÃ¡rio pedir explicitamente ("gere um relatÃ³rio", "salve", "quero o PDF"). Para perguntas diretas, responda com texto simples.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SESSÃƒO ATUAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DATA E HORA: ${now}
CHAT ID: ${chatId}
PERFIL DO USUÃRIO: ${currentUserRole}${authorityRule}`;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// WORKFLOW
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const claraWorkflow = new StateGraph<ClaraState>({
  channels: {
    messages: {
      reducer: messagesStateReducer,
      default: () => [] as BaseMessage[],
    },
    chat_id: {
      reducer: (_x, y) => y ?? _x,
      default: () => 0,
    },
    current_user_role: {
      reducer: (_x: any, y: any) => y ?? _x ?? "patient",
      default: () => "patient" as const,
    },
    research_brief: {
      reducer: (_x: string, y: string) => y ?? _x ?? "",
      default: () => "",
    },
    raw_notes: {
      reducer: (x: string[], y: string | string[]) => {
        if (Array.isArray(y) && y.length === 0) return [];
        const items = Array.isArray(y) ? y : typeof y === "string" ? [y] : [];
        return [...(x ?? []), ...items.filter(Boolean)];
      },
      default: () => [] as string[],
    },
    supervisor_messages: {
      reducer: (x: BaseMessage[], y: BaseMessage[] | BaseMessage) => {
        if (Array.isArray(y) && y.length === 0) return [];
        const incoming = Array.isArray(y) ? y : [y];
        return [...(x ?? []), ...incoming];
      },
      default: () => [] as BaseMessage[],
    },
    supervisor_iteration: {
      reducer: (_x: number, y: number) => (typeof y === "number" ? y : _x ?? 0),
      default: () => 0,
    },
    research_complete: {
      reducer: (_x: boolean, y: boolean) => (typeof y === "boolean" ? y : _x ?? false),
      default: () => false,
    },
    is_deep_research: {
      reducer: (_x: boolean, y: boolean) => (typeof y === "boolean" ? y : _x ?? false),
      default: () => false,
    },
    is_planning_mode: {
      reducer: (_x: boolean, y: boolean) => (typeof y === "boolean" ? y : _x ?? false),
      default: () => false,
    },
  },
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// NODE 1: classify_node
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const SIMPLE_KEYWORDS = [
  "oi", "olÃ¡", "ola", "tudo bem", "bom dia", "boa tarde", "boa noite",
  "obrigado", "obrigada", "valeu", "ok", "certo", "entendi", "beleza", "Ã³timo", "otimo",
];

const ClassifySchema = z.object({
  classification: z
    .enum(["simple", "research"])
    .describe("'simple' para conversa/pergunta direta. 'research' para anÃ¡lise de dados, relatÃ³rios ou investigaÃ§Ã£o de mÃºltiplos chats."),
  reasoning: z.string().describe("Justificativa em 1 frase."),
});

claraWorkflow.addNode("classify_node", async (state: ClaraState) => {
  const lastMessage = state.messages[state.messages.length - 1];
  const userText =
    typeof lastMessage?.content === "string"
      ? lastMessage.content
      : Array.isArray(lastMessage?.content)
        ? (lastMessage.content as Array<{ type: string; text?: string }>)
          .filter((c) => c.type === "text")
          .map((c) => c.text ?? "")
          .join(" ")
        : "";

  const researchStateReset = {
    research_complete: false,
    research_brief: "",
    raw_notes: [] as string[],
    supervisor_messages: [] as BaseMessage[],
    supervisor_iteration: 0,
    is_planning_mode: false,
  };

  if (userText.trim().startsWith("[PLANEJAR]")) {
    return { ...researchStateReset, is_deep_research: true, is_planning_mode: true };
  }

  const lower = userText.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "");
  const wordCount = lower.split(/\s+/).filter(Boolean).length;
  const isGreeting = SIMPLE_KEYWORDS.some(
    (kw) => lower === kw || lower.startsWith(kw + " ") || lower.endsWith(" " + kw)
  );
  if (isGreeting || wordCount <= 4) {
    return { ...researchStateReset, is_deep_research: false };
  }

  const today = new Date().toISOString().slice(0, 10);

  const CLASSIFIER_SYSTEM = `VocÃª Ã© um roteador de intenÃ§Ãµes para a Clara, assistente de clÃ­nica mÃ©dica.

Hoje: ${today}

REGRA FUNDAMENTAL:
"simple" = a resposta pode vir de MÃ‰TRICAS, LISTAS, DADOS ESTRUTURADOS ou INSIGHTS JÃ PROCESSADOS (tabela chat_insights). Inclui perguntas sobre objeÃ§Ãµes, gargalos, qualidade e notas, pois jÃ¡ existem insights salvos.
"research" = SOMENTE quando Ã© necessÃ¡rio LER o TEXTO BRUTO das conversas para anÃ¡lise semÃ¢ntica profunda (ex: tom de voz, padrÃµes de linguagem, anÃ¡lise de persuasÃ£o).

â†’ EXEMPLOS "simple" â€” responde com ferramentas diretas (SEM pipeline de pesquisa):
  â€¢ "Quantas conversas tivemos esta semana?" â†’ simple
  â€¢ "Volume de chats dia a dia" â†’ simple
  â€¢ "Picos de demanda desta semana" â†’ simple
  â€¢ "Quantos leads estÃ£o em qualified?" â†’ simple
  â€¢ "Qual o sentimento mÃ©dio dos leads?" â†’ simple
  â€¢ "Quais os chats mais recentes?" â†’ simple
  â€¢ "E quais foram as objeÃ§Ãµes levantadas na semana?" â†’ simple â† usa gerar_relatorio_qualidade_chats
  â€¢ "Quais os principais gargalos de atendimento?" â†’ simple â† usa gerar_relatorio_qualidade_chats
  â€¢ "Qual a nota mÃ©dia de atendimento?" â†’ simple â† usa gerar_relatorio_qualidade_chats
  â€¢ "RelatÃ³rio de qualidade desta semana" â†’ simple â† usa gerar_relatorio_qualidade_chats
  â€¢ "Mostre os leads com sentimento negativo" â†’ simple â† usa get_filtered_chats_list

â†’ EXEMPLOS "research" â€” SOMENTE para ler texto bruto de mensagens:
  â€¢ "Leia as conversas e me diga o que os pacientes mais reclamam" â†’ research (precisa LER texto)
  â€¢ "Analise o tom e linguagem das conversas desta semana" â†’ research (anÃ¡lise semÃ¢ntica)
  â€¢ "Quais argumentos de vendas funcionaram melhor?" â†’ research (precisa LER transcriÃ§Ãµes)

REGRA DE OURO: Se pode ser respondido com dados estruturados (contagens, listas, insights salvos) â†’ "simple". "research" Ã© APENAS para leitura e anÃ¡lise de texto bruto.`;

  try {
    const classifierModel = new ChatGoogleGenerativeAI({
      model: "gemini-3-flash-preview",
      apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY,
      temperature: 0,
    }).withStructuredOutput(ClassifySchema);

    const result = await classifierModel.invoke([
      new SystemMessage(CLASSIFIER_SYSTEM),
      new HumanMessage(userText),
    ]);

    return {
      ...researchStateReset,
      is_deep_research: result.classification === "research",
    };
  } catch {
    return { ...researchStateReset, is_deep_research: false };
  }
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// NODE 2: simple_agent
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

claraWorkflow.addNode("simple_agent", async (state: ClaraState) => {
  const { company, custom_rules, voice_rules } = await loadDynamicPromptParts();

  const model = new ChatGoogleGenerativeAI({
    model: "gemini-3-flash-preview",
    apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY,
    temperature: 0.3,
  });

  const modelWithTools = model.bindTools(simpleAgentTools);
  const systemPrompt = buildSystemPrompt(
    company, custom_rules, voice_rules, state.chat_id, state.current_user_role
  );

  const safeMessages = state.messages.length > 0
    ? state.messages
    : [new HumanMessage("OlÃ¡.")];

  const response = (await modelWithTools.invoke([
    new SystemMessage(systemPrompt),
    ...safeMessages,
  ])) as AIMessage;

  return { messages: [response] };
});

claraWorkflow.addNode("tools", new ToolNode(simpleAgentTools));

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// NODE 3: write_research_brief_node
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

claraWorkflow.addNode("write_research_brief_node", async (state: ClaraState) => {
  const lastMessage = state.messages[state.messages.length - 1];
  const userText =
    typeof lastMessage?.content === "string"
      ? lastMessage.content.replace(/^\[PLANEJAR\]\s*/i, "").trim()
      : Array.isArray(lastMessage?.content)
        ? (lastMessage.content as Array<{ type: string; text?: string }>)
          .filter((c) => c.type === "text")
          .map((c) => c.text ?? "")
          .join(" ")
          .replace(/^\[PLANEJAR\]\s*/i, "")
          .trim()
        : "";

  const today = new Date().toISOString().slice(0, 10);
  const yesterday = new Date(Date.now() - 86400000).toISOString().slice(0, 10);

  const BRIEF_SYSTEM = `VocÃª Ã© o Estrategista de Pesquisa da Clara. Sua funÃ§Ã£o Ã© transformar a solicitaÃ§Ã£o do usuÃ¡rio em um plano de pesquisa estruturado.

Hoje: ${today} | Ontem: ${yesterday}

BANCO DE DADOS DISPONÃVEL:
â€¢ chats: id, phone, contact_name, stage (new|em_triagem|agendando|fila_espera|qualified|lost|won|done), ai_sentiment (positive|negative|neutral), last_interaction_at (FILTRO DE DATA â€” base para "conversas ativas"), is_archived
â€¢ chat_messages: id, chat_id, sender (AI_AGENT=bot|HUMAN_AGENT=secretÃ¡ria|contact=paciente), message_text, created_at (FILTRO DE DATA)
â€¢ chat_insights: id, chat_id, nota_atendimento (0-10), sentimento, objecoes[], gargalos[], decisao, resumo_analise, updated_at
â€¢ clara_reports: id, titulo, conteudo_markdown, tipo, created_at
â€¢ clara_memories: id, memory_type, content, updated_at

FERRAMENTAS DISPONÃVEIS (EM ORDEM DE PRIORIDADE):
â€¢ get_volume_metrics(start_date, end_date) â€” â­ USAR PRIMEIRO para volume de conversas, mensagens, picos por dia. DeterminÃ­stico, sem LLM.
â€¢ execute_sql(sql) â€” Para qualquer outra mÃ©trica: agendamentos, financeiro, JOINs. O researcher escreve o SQL diretamente. Datas BRT: '2026-02-24T00:00:00-03:00'::timestamptz
â€¢ get_filtered_chats_list â€” Lista chats com detalhes de contato por filtros
â€¢ get_chat_cascade_history â€” HistÃ³rico de um chat especÃ­fico
â€¢ deep_research_chats â€” AnÃ¡lise semÃ¢ntica de conteÃºdo de mÃºltiplos chats
â€¢ analisar_chat_especifico â€” AnÃ¡lise estruturada com insights por chat
â€¢ gerar_relatorio_qualidade_chats â€” MÃ©tricas de qualidade de chat_insights
â€¢ save_report â€” Persiste relatÃ³rio no banco

Escreva um brief de pesquisa conciso (mÃ¡x 250 palavras). Para relatÃ³rios de volume, especifique que o researcher deve chamar get_volume_metrics com datas YYYY-MM-DD. Para outras mÃ©tricas, especifique o SQL que o researcher deve executar via execute_sql.`;

  const model = new ChatGoogleGenerativeAI({
    model: "gemini-3-flash-preview",
    apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY,
    temperature: 0,
  });

  const response = await model.invoke([
    new SystemMessage(BRIEF_SYSTEM),
    new HumanMessage(`Crie o brief de pesquisa para: "${userText}"`),
  ]);

  const brief =
    typeof response.content === "string"
      ? response.content
      : Array.isArray(response.content)
        ? (response.content as Array<any>).map((c) => c?.text ?? "").join("")
        : "";

  if (state.is_planning_mode) {
    const planMessage = new AIMessage(
      `ğŸ“‹ **Plano de Pesquisa**\n\n${brief}\n\n---\n*Para executar este plano, envie a mesma mensagem sem o prefixo [PLANEJAR].*`
    );
    return {
      research_brief: brief,
      messages: [planMessage],
      research_complete: true,
    };
  }

  return { research_brief: brief, research_complete: false };
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// NODE 4: research_supervisor_node
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const SupervisorDecisionSchema = z.object({
  action: z
    .enum(["conduct_research", "research_complete"])
    .describe("Escolha 'conduct_research' para enviar pesquisadores para coletar dados ou 'research_complete' se os dados jÃ¡ foram coletados ou a pesquisa acabou."),
  research_tasks: z
    .array(
      z.object({
        topic: z.string().describe("TÃ­tulo curto do tÃ³pico a investigar."),
        description: z.string().describe("InstruÃ§Ã£o EXATA de qual ferramenta usar: get_volume_metrics com datas, ou execute_sql com o SQL completo a executar."),
      })
    )
    .max(5)
    .optional()
    .describe("Lista de tarefas. OBRIGATÃ“RIO preencher se action = 'conduct_research'."),
  reason: z
    .string()
    .optional()
    .describe("Motivo do encerramento. Preencher se action = 'research_complete'."),
});

claraWorkflow.addNode("research_supervisor_node", async (state: ClaraState) => {
  const today = new Date().toISOString().slice(0, 10);
  const sevenDaysAgo = new Date(Date.now() - 7 * 86400000).toISOString().slice(0, 10);

  let insightCount = 0;
  let recentChatsCount = 0;

  if (state.supervisor_iteration === 0) {
    try {
      const supabase = getSupabaseAdminClient();
      const [insightRes, recentRes] = await Promise.all([
        supabase.from("chat_insights").select("*", { count: "exact", head: true })
          .gte("updated_at", new Date(Date.now() - 90 * 86400000).toISOString()),
        supabase.from("chats").select("*", { count: "exact", head: true })
          .gte("last_interaction_at", new Date(Date.now() - 7 * 86400000).toISOString())
          .eq("is_archived", false),
      ]);
      insightCount = insightRes.count ?? 0;
      recentChatsCount = recentRes.count ?? 0;
      console.log(`â„¹ï¸ [Supervisor] Contexto Global Lido -> Insights(90d): ${insightCount} | Chats Ativos(7d): ${recentChatsCount}`);
    } catch (e: any) {
      console.warn("âš ï¸ [Supervisor] Falha ao coletar contexto:", e?.message);
    }
  }

  const rawNotesContext =
    state.raw_notes.length > 0
      ? `\n\nDados jÃ¡ coletados pelos researchers:\n${state.raw_notes
        .map((note, i) => `--- Researcher ${i + 1} ---\n${note}`)
        .join("\n\n")}`
      : "";

  const SUPERVISOR_SYSTEM = `VocÃª Ã© o Supervisor de Pesquisa da Clara. Sua funÃ§Ã£o Ã© gerar tarefas precisas para os researchers coletarem dados do banco.

Hoje: ${today}
IteraÃ§Ã£o atual: ${state.supervisor_iteration + 1}/${MAX_SUPERVISOR_ITERATIONS}

DADOS GLOBAIS DA CLÃNICA (Status Real):
- Chats com atividade nos Ãºltimos 7 dias: ${recentChatsCount}
- Insights de qualidade processados (90 dias): ${insightCount}

BRIEF DE PESQUISA:
${state.research_brief}
${rawNotesContext}

GUIA DE FERRAMENTAS PARA AS TASKS:
â€¢ get_volume_metrics(start_date, end_date) â†’ USE PRIMEIRO para volume de chats/mensagens por dia. Datas: YYYY-MM-DD.
  Exemplo de task: "Chame get_volume_metrics com start_date='${sevenDaysAgo}' e end_date='${today}'"
â€¢ execute_sql(sql) â†’ Para agendamentos, financeiro, pacientes, qualquer JOIN. O researcher escreve o SQL.
  Exemplo de task: "Execute: SELECT stage, COUNT(*) FROM chats WHERE last_interaction_at >= '${sevenDaysAgo}T00:00:00-03:00'::timestamptz GROUP BY stage"
â€¢ get_filtered_chats_list â†’ Listar chats com detalhes de contato (stage, sentimento, data)
â€¢ deep_research_chats â†’ Analisar conteÃºdo semÃ¢ntico de conversas (objeÃ§Ãµes, padrÃµes)

REGRA: Nunca instrua generate_sql_report ou query_database â€” essas ferramentas foram removidas.

INSTRUÃ‡Ã•ES:
1. Na iteraÃ§Ã£o 1 (raw_notes vazio), escolha OBRIGATORIAMENTE action="conduct_research" e preencha "research_tasks".
2. Tarefas devem ser explÃ­citas: diga qual ferramenta chamar e com quais parÃ¢metros.
3. Somente escolha "research_complete" se raw_notes JÃ tiver dados REAIS coletados.`;

  const model = new ChatGoogleGenerativeAI({
    model: "gemini-3-flash-preview",
    apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY,
    temperature: 0,
  }).withStructuredOutput(SupervisorDecisionSchema);

  let decision: z.infer<typeof SupervisorDecisionSchema>;

  try {
    decision = await model.invoke([
      new SystemMessage(SUPERVISOR_SYSTEM),
      new HumanMessage("Analise o brief e os dados. Qual Ã© a prÃ³xima aÃ§Ã£o? Na iteraÃ§Ã£o 1, preencha research_tasks e nÃ£o encerre a pesquisa."),
    ]);
  } catch (e: any) {
    console.error("âš ï¸ [Supervisor] Erro no Parse/LLM. ForÃ§ando pesquisa de emergÃªncia!", e.message);
    decision = {
      action: "conduct_research",
      research_tasks: [
        {
          topic: "Volume Bruto de Chats (Fallback)",
          description: `Chame get_volume_metrics com start_date='${sevenDaysAgo}' e end_date='${today}' para obter o volume de conversas e mensagens dia a dia dos Ãºltimos 7 dias.`,
        },
      ],
    };
  }

  if (decision.action === "research_complete" && state.supervisor_iteration === 0) {
    console.warn("âš ï¸ [Supervisor] LLM tentou abortar na iteraÃ§Ã£o 0. Interceptado e forÃ§ado a pesquisar.");
    decision = {
      action: "conduct_research",
      research_tasks: [
        {
          topic: "Volume de Chats Recentes",
          description: `Chame get_volume_metrics com start_date='${sevenDaysAgo}' e end_date='${today}' para obter o volume de conversas e mensagens dia a dia dos Ãºltimos 7 dias.`,
        },
      ],
    };
  }

  const EMPTY_INDICATORS = [
    "nenhum dado", "nenhum insight", "nÃ£o foram encontrados", "sem dados",
    "nenhuma interaÃ§Ã£o", "0 chats", "nÃ£o possui registros", "nÃ£o retornou registros",
    "ainda nÃ£o foram submetidos", "dados brutos existem", "sem registros processados",
    "nenhum chat encontrado", "nenhum resultado", "falha"
  ];

  const hasNoData =
    state.raw_notes.length === 0 ||
    state.raw_notes.every((n) => {
      if (!n?.trim()) return true;
      const lower = n.toLowerCase();
      return EMPTY_INDICATORS.some((indicator) => lower.includes(indicator));
    });

  if (decision.action === "research_complete" && hasNoData && state.supervisor_iteration < MAX_SUPERVISOR_ITERATIONS - 1) {
    decision = {
      action: "conduct_research",
      research_tasks: [
        {
          topic: "Pesquisa ForÃ§ada de Volume",
          description: `Chame get_volume_metrics com start_date='${sevenDaysAgo}' e end_date='${today}' para obter o volume de conversas e mensagens dia a dia dos Ãºltimos 7 dias. Esta Ã© a ferramenta correta para dados de volume â€” use-a imediatamente.`,
        },
      ],
    };
  }

  if (decision.action === "research_complete") {
    const reasonText = decision.reason || "DecisÃ£o do LLM";
    const supervisorMsg = new AIMessage(`Pesquisa concluÃ­da apÃ³s ${state.supervisor_iteration + 1} iteraÃ§Ã£o(Ãµes). ${reasonText}`);
    return {
      research_complete: true,
      supervisor_messages: [supervisorMsg],
      supervisor_iteration: state.supervisor_iteration + 1,
    };
  }

  const tasks = decision.research_tasks || [];

  const researchResults = await Promise.all(
    tasks.map((task) =>
      researcherGraph
        .invoke({
          research_topic: `${task.topic}: ${task.description}`,
          researcher_messages: [],
          raw_notes: [],
          compressed_research: "",
          iteration: 0,
        })
        .catch((e: Error) => ({
          compressed_research: `[Erro no researcher "${task.topic}": ${e.message}]`,
          raw_notes: [],
        }))
    )
  );

  const newNotes = researchResults
    .map((r) => (r as any).compressed_research as string | undefined)
    .filter((n): n is string => typeof n === "string" && n.trim().length > 0);

  const supervisorMsg = new AIMessage(
    `Rodada ${state.supervisor_iteration + 1}: ${tasks.length} researcher(s) executados.`
  );

  return {
    raw_notes: newNotes,
    supervisor_messages: [supervisorMsg],
    supervisor_iteration: state.supervisor_iteration + 1,
    research_complete: false,
  };
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// NODE 5: final_report_node
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

claraWorkflow.addNode("final_report_node", async (state: ClaraState) => {
  const { custom_rules } = await loadDynamicPromptParts();

  // Usa gemini-3.1-pro-preview para sÃ­ntese de relatÃ³rio de maior qualidade
  const model = new ChatGoogleGenerativeAI({
    model: "gemini-3.1-pro-preview",
    apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY,
    temperature: 0.3,
  });

  const rawNotesText = state.raw_notes
    .map((note, i) => `=== Researcher ${i + 1} ===\n${note}`)
    .join("\n\n");

  const today = new Date().toISOString().slice(0, 10);

  const REPORT_SYSTEM = `${CLARA_SYSTEM_PROMPT}

${custom_rules ? `REGRAS APRENDIDAS:\n${custom_rules}` : ""}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INSTRUÃ‡Ã•ES DO RELATÃ“RIO FINAL E REGRAS ANTI-ALUCINAÃ‡ÃƒO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VocÃª recebeu os achados consolidados do sistema sobre a seguinte solicitaÃ§Ã£o:

BRIEF: ${state.research_brief}

Sua tarefa Ã© sintetizar esses dados em um relatÃ³rio Markdown elegante, estruturado e profissional para a clÃ­nica.

REGRAS DE CONDUTA, SIGILO E VERACIDADE (OBRIGATÃ“RIAS E INQUEBRÃVEIS):
1. â›” SIGILO DE SISTEMA (ANTI-VAZAMENTO): NUNCA mencione processos internos. PALAVRAS PROIBIDAS: "pesquisadores", "researchers", "banco de dados", "SQL", "query", "tabelas", "motor de anÃ¡lise", "LangGraph", "raw_notes", "ferramentas". Aja com total naturalidade humana.
2. â›” VERACIDADE ABSOLUTA (ANTI-ALUCINAÃ‡ÃƒO): Ã‰ ESTRITAMENTE PROIBIDO inventar, deduzir ou fabricar nomes, IDs de chats, telefones, estÃ¡gios, sentimentos ou nÃºmeros de volume. VocÃª DEVE usar APENAS e EXATAMENTE os dados numÃ©ricos e as listas fornecidos abaixo na seÃ§Ã£o "DADOS COLETADOS NO SISTEMA". Se o dado nÃ£o estÃ¡ escrito ali, ele NÃƒO existe.
3. COMPORTAMENTO EM CASO DE DADOS VAZIOS: Se a seÃ§Ã£o "DADOS COLETADOS NO SISTEMA" relatar falha ou estiver vazia, VOCÃŠ ESTÃ PROIBIDA DE GERAR O RELATÃ“RIO. NÃ£o invente nada. PeÃ§a desculpas educadamente, explique que nÃ£o hÃ¡ volume registrado.
4. PRESERVAÃ‡ÃƒO DE DADOS REAIS: Preserve TODOS os links de chats no formato [[chat:ID|Nome (Telefone)]] EXATAMENTE como recebidos dos dados crus.
5. Se os dados forem reais, fartos e concretos, crie o relatÃ³rio com seÃ§Ãµes e inclua a tabela "ğŸ“ Amostra de Chats" com as colunas | Chat | Sentimento | Stage |.
6. Data de referÃªncia atual: ${today}.

DADOS COLETADOS NO SISTEMA:
${rawNotesText || "[Nenhum dado consolidado foi encontrado para este pedido. Aja naturalmente informando que nÃ£o possui esses registros no momento, sem inventar dados.]"}`;

  const response = (await model.invoke([
    new SystemMessage(REPORT_SYSTEM),
    new HumanMessage(
      "Sintetize os dados recebidos. AtenÃ§Ã£o mÃ¡xima Ã  regra Anti-AlucinaÃ§Ã£o e de Sigilo Absoluto: nÃ£o invente dados."
    ),
  ])) as AIMessage;

  const reportText =
    typeof response.content === "string"
      ? response.content
      : Array.isArray(response.content)
        ? (response.content as Array<any>).map((c) => c?.text ?? "").join("")
        : "";

  // Salva automaticamente apenas quando o brief indica que o usuÃ¡rio pediu um relatÃ³rio formal
  const saveKeywords = /\b(salvar|save|gere um relat[oÃ³]rio|gerar relat[oÃ³]rio|relat[oÃ³]rio formal|export|pdf)\b/i;
  const shouldAutoSave = saveKeywords.test(state.research_brief) ||
    saveKeywords.test((state.messages[state.messages.length - 1]?.content as string) ?? "");

  if (shouldAutoSave) {
    try {
      const supabase = getSupabaseAdminClient();
      const titulo = `RelatÃ³rio â€” ${new Date().toLocaleDateString("pt-BR")}`;
      const { data: saved, error: saveError } = await (supabase as any)
        .from("clara_reports")
        .insert({ titulo, conteudo_markdown: reportText, tipo: "analise_chats", created_at: new Date().toISOString() })
        .select("id")
        .single();

      if (!saveError) {
        const reportId = (saved as any)?.id;
        if (reportId) {
          console.log(`âœ… [Clara] RelatÃ³rio salvo â€” ID #${reportId}`);
          return {
            messages: [new AIMessage(
              `${reportText}\n\n---\nğŸ“„ *RelatÃ³rio salvo â€” ID #${reportId}. Acesse em /relatorios/${reportId}*`
            )],
          };
        }
      } else {
        console.error("âŒ [Clara] Erro ao salvar relatÃ³rio:", saveError.message);
      }
    } catch (e: any) {
      console.error("âŒ [Clara] ExceÃ§Ã£o ao salvar relatÃ³rio:", e?.message ?? e);
    }
  }

  return { messages: [new AIMessage(reportText)] };
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// EDGES
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// @ts-expect-error
claraWorkflow.addEdge(START, "classify_node");

// @ts-expect-error
claraWorkflow.addConditionalEdges("classify_node", (state: ClaraState) => {
  return state.is_deep_research ? "write_research_brief_node" : "simple_agent";
});

// @ts-expect-error
claraWorkflow.addConditionalEdges("simple_agent", toolsCondition);

// @ts-expect-error
claraWorkflow.addEdge("tools", "simple_agent");

// @ts-expect-error
claraWorkflow.addConditionalEdges("write_research_brief_node", (state: ClaraState) => {
  return state.research_complete ? END : "research_supervisor_node";
});

// @ts-expect-error
claraWorkflow.addConditionalEdges("research_supervisor_node", (state: ClaraState) => {
  if (state.research_complete || state.supervisor_iteration >= MAX_SUPERVISOR_ITERATIONS) {
    return "final_report_node";
  }
  return "research_supervisor_node";
});

// @ts-expect-error
claraWorkflow.addEdge("final_report_node", END);

export const claraGraph = claraWorkflow.compile({ checkpointer: postgresCheckpointer });